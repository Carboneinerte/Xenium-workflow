{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_notebook = '/media/volume/volume_spatial/hugo/notebook'\n",
    "\n",
    "# # ### circa2_\n",
    "samples = ['circa2-ZT01','circa2-ZT05','circa2-ZT09','circa2-ZT13','circa2-ZT17','circa2-ZT21']\n",
    "samples_ids = ['circa2_ZT01','circa2_ZT05','circa2_ZT09','circa2_ZT13','circa2_ZT17','circa2_ZT21',]\n",
    "name_dir = 'circa2'\n",
    "\n",
    "# samples = [\"S1_Region1\", \"S1_Region2\", \"S2_Region1\",\"S2_Region2\"]\n",
    "# samples_ids = [\"S1-Region1\", \"S1-Region2\", \"S2-Region1\",\"S2-Region2\"]\n",
    "# name_dir = \"last_test\"\n",
    "\n",
    "# dir_ = {'circa2-ZT01' : \"/media/volume/volume_spatial/hugo/data\",\n",
    "#         'circa2-ZT05' : \"/media/volume/volume_spatial/hugo/data\",\n",
    "#         'circa2-ZT09' : \"/media/volume/volume_spatial/hugo/data\",\n",
    "#         'circa2-ZT13' : \"/media/volume/volume_spatial/hugo/data\",\n",
    "#         'circa2-ZT17' : \"/media/volume/volume_spatial/hugo/data\",\n",
    "#         'circa2-ZT21' : \"/media/volume/volume_spatial/hugo/data\",\n",
    "#         \"S1_Region1\" : '/media/volume/volume_spatial/hugo/data',\n",
    "#         \"S1_Region2\" : '/media/volume/volume_spatial/hugo/data',\n",
    "#         \"S2_Region1\" : '/media/volume/volume_spatial/hugo/data',\n",
    "#         \"S2_Region2\" : '/media/volume/volume_spatial/hugo/data',\n",
    "#         \"3159-1\" : '/media/volume/volume_spatial/hugo/data',\n",
    "#         \"3160-1\" : '/media/volume/volume_spatial/hugo/data'\n",
    "#        }\n",
    "\n",
    "# dir_ = \"/media/volume/volume_spatial/hugo/data\"\n",
    "\n",
    "dir_ = 'F:\\Xenium\\Hugo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# samples = ['circa2-ZT01','circa2-ZT05','circa2-ZT09','circa2-ZT13','circa2-ZT17','circa2-ZT21']\n",
    "# samples_ids = ['circa2_ZT01','circa2_ZT05','circa2_ZT09','circa2_ZT13','circa2_ZT17','circa2_ZT21',]\n",
    "\n",
    "samples = ['3159-2', \"3160-1\", \"3159-1\", \"3161-1\",]\n",
    "samples_ids = ['3159-2', \"3160-1\", \"3159-1\", \"3161-1\",]\n",
    "\n",
    "### create a scanpy objects for each sample and create a unique cell name for each cell\n",
    "def top_genes_():\n",
    "    list_ = []\n",
    "    for sample, sample_id in zip(samples, samples_ids):\n",
    "        # transcript_count = pd.read_parquet(f'{dir_}/{sample}/transcripts.parquet')\n",
    "        transcript_count = pd.read_parquet(f'{dir_}\\\\{sample}\\\\transcripts.parquet')\n",
    "\n",
    "        transcript_count = transcript_count[(~transcript_count['feature_name'].str.contains('_')) & (transcript_count['qv']>=20)]\n",
    "        transcript_count = transcript_count['feature_name'].value_counts()\n",
    "        transcript_count = transcript_count.sort_index()\n",
    "        list_.append(transcript_count)\n",
    "\n",
    "    return list_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_counts = pd.read_parquet(f'{dir_}\\\\3159-1\\\\transcripts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = top_genes_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def spearcor_(test_list):\n",
    "    nb_sample = len(test_list)\n",
    "    dict_list = {}\n",
    "    for n in range(0,nb_sample):\n",
    "        stat_ = stats.pearsonr(x=test_list[0].sort_index(), y = test_list[n].sort_index())\n",
    "        dict_temp = {samples[n]:round(stat_[0],3)}\n",
    "        dict_list.update(dict_temp)\n",
    "\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = spearcor_(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_coor(dict_list):\n",
    "    x = list(dict_list.keys())\n",
    "    y = list(dict_list.values())\n",
    "    low = min(y) - 0.01\n",
    "    high = max(y) + 0.01\n",
    "    plt.bar(x,y)\n",
    "    plt.ylim(low,high)\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coor(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_count = transcript_count[(~transcript_count['feature_name'].str.contains('_')) & (transcript_count['qv']>=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_count_values = transcript_count['feature_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_count_values_top300 = transcript_count_values[0:300].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[\"transcript_\"+str(sample_ids)] = transcript_count_values_top300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_circa2_ZT01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_CTRL = \"circa2-ZT01\"\n",
    "dir_ = 'D:/Xenium'\n",
    "transcript_count_CTRL = pd.read_parquet(f'{dir_}/{sample_CTRL}/transcripts.parquet')\n",
    "transcript_count_CTRL = transcript_count_CTRL[(~transcript_count_CTRL['feature_name'].str.contains('_')) & (transcript_count_CTRL['qv']>=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_TEST = \"S1_Region1\"\n",
    "transcript_count_TEST = pd.read_parquet(f'{dir_}/{sample_TEST}/transcripts.parquet')\n",
    "transcript_count_TEST = transcript_count_TEST[(~transcript_count_TEST['feature_name'].str.contains('_')) & (transcript_count_TEST['qv']>=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_count_CTRL_all = transcript_count_CTRL['feature_name'].value_counts()\n",
    "transcript_count_CTRL_all = transcript_count_CTRL_all.sort_index()\n",
    "transcript_count_TEST_all = transcript_count_TEST['feature_name'].value_counts()\n",
    "transcript_count_TEST_all = transcript_count_TEST_all.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'CTRL' : transcript_count_CTRL_all.values, 'TEST' : transcript_count_TEST_all.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = d, index = transcript_count_TEST_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CTRL4'] = df['CTRL'] / 4\n",
    "df['Percent'] = df['CTRL'] / df['TEST']\n",
    "df['Percent4'] = df['CTRL4'] / df['TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('correlation_transcript_XeniumTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Percent').tail(10),df.sort_values(by='Percent').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=range(5006), y = df['Percent4'].sort_values())\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.hlines(y=1, xmin=0, xmax=5006)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stat_ = stats.pearsonr(x=transcript_count_CTRL_all, y = transcript_count_TEST_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(x=transcript_count_CTRL_all, y = transcript_count_TEST_all)\n",
    "plt.xlabel(sample_CTRL)\n",
    "plt.ylabel(sample_TEST)\n",
    "plt.title(f'Spearson correlation : {round(stat_[0],3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
